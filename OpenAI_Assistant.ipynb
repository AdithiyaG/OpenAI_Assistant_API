{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V28",
      "authorship_tag": "ABX9TyP1dd5NoFq6/WQmVAQCNirG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AdithiyaG/OpenAI_Assistant_API/blob/main/OpenAI_Assistant.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "jLv74_ag3m-L"
      },
      "outputs": [],
      "source": [
        "!pip install -q openai\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create an Assitant"
      ],
      "metadata": {
        "id": "H_M9ZPXBGB1F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import AzureOpenAI"
      ],
      "metadata": {
        "id": "RueICjNr5wz4"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "api_key=userdata.get('OPENAI_API_KEY')\n",
        "api_base=userdata.get('OPENAI_ENDPOINT')"
      ],
      "metadata": {
        "id": "WKB2gJc0-Fya"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "client = AzureOpenAI(\n",
        "        azure_endpoint=api_base,\n",
        "        api_key=api_key,\n",
        "        api_version=\"2024-02-15-preview\"\n",
        "    )"
      ],
      "metadata": {
        "id": "9mP1FusU-DEu"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "assistant = client.beta.assistants.create(\n",
        "    name=\"Math tutor\",\n",
        "    instructions=\"You are personl math tutor. Write and run a code to answer math questions.\",\n",
        "    tools=[{\"type\":\"code_interpreter\"}],\n",
        "    model=\"gpt-4-32k\",\n",
        ")"
      ],
      "metadata": {
        "id": "JFdAsLSL530V"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Thread\n",
        "A **Thread** class represents a conversation between user and one or many assitants"
      ],
      "metadata": {
        "id": "I3ovXZrT-51G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create a Thread"
      ],
      "metadata": {
        "id": "EpRU9Jsn_OAW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "thread=client.beta.threads.create()"
      ],
      "metadata": {
        "id": "1jlcyeCV-0Ve"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "thread"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eKM3UUy0EWhp",
        "outputId": "75f5c79b-060d-4ccd-e3a5-a7fb762fb523"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Thread(id='thread_DBf5wUKKUqv4Awr6MyBN2AsH', created_at=1714028517, metadata={}, object='thread', tool_resources=None)"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Add messages to Thread\n",
        "\n",
        "\n",
        "*   Contents of message between users or applications are added as Message objects\n",
        "*   There is no limit to number messages you can add to Threads, its truncate any content that doesn't fit into model's context window\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "uKxNFvbQ_UnO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "message=client.beta.threads.messages.create(\n",
        "    thread_id=thread.id,\n",
        "    role=\"user\",\n",
        "    content=\"I need to solve the equation `3x + 11 =14`.Can you help me?\"\n",
        ")"
      ],
      "metadata": {
        "id": "MBelvlXO-5WQ"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "message"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xaoQS11aEZFJ",
        "outputId": "5558f0c1-0dbb-475b-e7ac-d07cc2620ea7"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Message(id='msg_f1kMKengW0rf6ZmH85X0WsMH', assistant_id=None, attachments=None, completed_at=None, content=[TextContentBlock(text=Text(annotations=[], value='I need to solve the equation `3x + 11 =14`.Can you help me?'), type='text')], created_at=1714028525, incomplete_at=None, incomplete_details=None, metadata={}, object='thread.message', role='user', run_id=None, status=None, thread_id='thread_DBf5wUKKUqv4Awr6MyBN2AsH', file_ids=[])"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create a Run\n",
        "\n",
        "*   Once all messages are added to thread\n",
        "*   You can run thread using any assitant\n",
        "*   Creating a run uses model and tools associated with Assitant to generate a response\n",
        "* These responses are added to thread as ```assitant``` Messages\n",
        "\n"
      ],
      "metadata": {
        "id": "pcx0qEZGEowG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Without Streaming"
      ],
      "metadata": {
        "id": "U2dqnDc1Fej3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "run = client.beta.threads.runs.create_and_poll(\n",
        "    thread_id=thread.id,\n",
        "    assistant_id=assistant.id,\n",
        "    instructions=\"Please address the user as Jane Doe.The user has a premium account\"\n",
        ")"
      ],
      "metadata": {
        "id": "JPCkDoZ7EDsN"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "run"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a4ZcnTecG5Mp",
        "outputId": "36bbdcea-efc7-4d30-c1b8-81a8f250476d"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Run(id='run_gm5OL0KS4jaKK2TQo0dlaK5x', assistant_id='asst_uKwfyzISrRc5cUNukw4YJFGi', cancelled_at=None, completed_at=1714029285, created_at=1714029208, expires_at=None, failed_at=None, incomplete_details=None, instructions='Please address the user as Jane Doe.The user has a premium account', last_error=None, max_completion_tokens=None, max_prompt_tokens=None, metadata={}, model='gpt-4-32k', object='thread.run', required_action=None, response_format=None, started_at=1714029209, status='completed', thread_id='thread_DBf5wUKKUqv4Awr6MyBN2AsH', tool_choice=None, tools=[CodeInterpreterTool(type='code_interpreter')], truncation_strategy=None, usage=Usage(completion_tokens=382, prompt_tokens=3595, total_tokens=3977), temperature=1.0, top_p=None, file_ids=[])"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if run.status == 'completed':\n",
        "  messages = client.beta.threads.messages.list(\n",
        "      thread_id=thread.id\n",
        "  )\n",
        "  print(messages)\n",
        "else:\n",
        "  print(run.status)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3dTmRuLcGkoC",
        "outputId": "24383b29-d49b-4443-823c-fa09ac288dcc"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SyncCursorPage[Message](data=[Message(id='msg_acTxz4goDAnoP5j7mlOGwFLx', assistant_id='asst_uKwfyzISrRc5cUNukw4YJFGi', attachments=None, completed_at=None, content=[TextContentBlock(text=Text(annotations=[], value=\"I'm really sorry for the inconvenience, Jane Doe. We might be experiencing some technical difficulties. We will get this sorted out as soon as possible.\"), type='text')], created_at=1714029271, incomplete_at=None, incomplete_details=None, metadata={}, object='thread.message', role='assistant', run_id='run_gm5OL0KS4jaKK2TQo0dlaK5x', status=None, thread_id='thread_DBf5wUKKUqv4Awr6MyBN2AsH', file_ids=[]), Message(id='msg_0mzQdkPJH223LbJOZ2TvJOVI', assistant_id='asst_uKwfyzISrRc5cUNukw4YJFGi', attachments=None, completed_at=None, content=[TextContentBlock(text=Text(annotations=[], value=\"I apologize for the inconvenience, Jane Doe. It seems there was an issue with the computation, probably due to a connection error. Let's try again.\"), type='text')], created_at=1714029253, incomplete_at=None, incomplete_details=None, metadata={}, object='thread.message', role='assistant', run_id='run_gm5OL0KS4jaKK2TQo0dlaK5x', status=None, thread_id='thread_DBf5wUKKUqv4Awr6MyBN2AsH', file_ids=[]), Message(id='msg_tCGM8JbjuqJAwQ2hcoxd1m1y', assistant_id='asst_uKwfyzISrRc5cUNukw4YJFGi', attachments=None, completed_at=None, content=[TextContentBlock(text=Text(annotations=[], value=\"Apologies for the confusion earlier, Jane Doe. I made a mistake in the code. Let's correct this and solve the equation `3x + 11 = 14`.\"), type='text')], created_at=1714029242, incomplete_at=None, incomplete_details=None, metadata={}, object='thread.message', role='assistant', run_id='run_gm5OL0KS4jaKK2TQo0dlaK5x', status=None, thread_id='thread_DBf5wUKKUqv4Awr6MyBN2AsH', file_ids=[]), Message(id='msg_wdE0xn58yqb6m0wF8cwALePt', assistant_id='asst_uKwfyzISrRc5cUNukw4YJFGi', attachments=None, completed_at=None, content=[TextContentBlock(text=Text(annotations=[], value=\"I apologize for the inconvenience, Jane Doe. It seems that an unexpected error occurred while processing the request. Let's try again.\"), type='text')], created_at=1714029231, incomplete_at=None, incomplete_details=None, metadata={}, object='thread.message', role='assistant', run_id='run_gm5OL0KS4jaKK2TQo0dlaK5x', status=None, thread_id='thread_DBf5wUKKUqv4Awr6MyBN2AsH', file_ids=[]), Message(id='msg_JSmKoR5QNJDwO1J0OgTuHI8s', assistant_id='asst_uKwfyzISrRc5cUNukw4YJFGi', attachments=None, completed_at=None, content=[TextContentBlock(text=Text(annotations=[], value=\"Sure, Jane Doe. In order to solve `3x + 11 = 14` for `x`, we need to isolate `x`. We can first subtract `11` from both sides, then divide by `3`. Let's do that for you.\"), type='text')], created_at=1714029214, incomplete_at=None, incomplete_details=None, metadata={}, object='thread.message', role='assistant', run_id='run_gm5OL0KS4jaKK2TQo0dlaK5x', status=None, thread_id='thread_DBf5wUKKUqv4Awr6MyBN2AsH', file_ids=[]), Message(id='msg_f1kMKengW0rf6ZmH85X0WsMH', assistant_id=None, attachments=None, completed_at=None, content=[TextContentBlock(text=Text(annotations=[], value='I need to solve the equation `3x + 11 =14`.Can you help me?'), type='text')], created_at=1714028525, incomplete_at=None, incomplete_details=None, metadata={}, object='thread.message', role='user', run_id=None, status=None, thread_id='thread_DBf5wUKKUqv4Awr6MyBN2AsH', file_ids=[])], object='list', first_id='msg_acTxz4goDAnoP5j7mlOGwFLx', last_id='msg_f1kMKengW0rf6ZmH85X0WsMH', has_more=False)\n"
          ]
        }
      ]
    }
  ]
}